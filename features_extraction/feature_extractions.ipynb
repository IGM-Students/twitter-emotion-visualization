{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Extract features from a penultimate layer in Emotion English DistilRoBERTa-base model"
      ],
      "metadata": {
        "id": "TgE9B3kso7fQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkIt7_lKp0h-"
      },
      "source": [
        "# install the transformers library\n",
        "!pip install transformers\n",
        "\n",
        "# import required packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# work with cuda\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZNal9hXp6wm"
      },
      "source": [
        "# load tokenizer and model\n",
        "model_name = \"j-hartmann/emotion-english-distilroberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparation of dataset"
      ],
      "metadata": {
        "id": "UArW7snAsKew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Option 1** list of texts\n",
        "\n"
      ],
      "metadata": {
        "id": "bMF9r3xYB9FF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHEzNB5Up5Yc"
      },
      "source": [
        "# create list of texts\n",
        "pred_texts = ['I like that', 'That is annoying', 'This is great!', 'WouldnÂ´t recommend it.']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Option 2** texts from csv file"
      ],
      "metadata": {
        "id": "fIrhZfeaEG3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run cell and select file for upload\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "KvZ9iYQIEXFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specify your filename\n",
        "\n",
        "# note: you can right-click on your file and copy-paste the path to it here\n",
        "file_name = \"/content/test.csv\" \n",
        "\n",
        " # select the column in your csv that contains the text to be classified\n",
        "text_column = \"text\"\n",
        "\n",
        "# read in csv\n",
        "df_pred = pd.read_csv(file_name)\n",
        "pred_texts = df_pred[text_column].dropna().astype('str').tolist()"
      ],
      "metadata": {
        "id": "MXOgjGMmGdQX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions for extracting"
      ],
      "metadata": {
        "id": "ghQiPaVzCRRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(name):\n",
        "    def hook(model, input, output):\n",
        "        features[name] = output.detach()\n",
        "    return hook"
      ],
      "metadata": {
        "id": "17uoYUFSfDHc"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier.dense.register_forward_hook(get_features('feats'))"
      ],
      "metadata": {
        "id": "DgVs2qkWfJJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract features from penultimate layer"
      ],
      "metadata": {
        "id": "GBXclXZitsg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# placeholders\n",
        "PREDICTIONS = []\n",
        "FEATS = []\n",
        "\n",
        "# placeholder for batch features\n",
        "features = {}\n",
        "\n",
        "for idx, inputs in enumerate(pred_texts):\n",
        "     \n",
        "    inputs = tokenizer(inputs, return_tensors=\"pt\")\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    predictions=model(**inputs).logits\n",
        "\n",
        "    PREDICTIONS.append(predictions.detach().cpu().numpy())\n",
        "    FEATS.append(features['feats'].cpu().numpy())\n",
        "       "
      ],
      "metadata": {
        "id": "LEyuTKUp5PW3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect features\n",
        "\n",
        "PREDICTIONS = np.concatenate(PREDICTIONS)\n",
        "FEATS = np.concatenate(FEATS)\n",
        "\n",
        "print('preds shape:', PREDICTIONS.shape)\n",
        "print('feats shape:', FEATS.shape)"
      ],
      "metadata": {
        "id": "_ybn8Qi74l9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize results\n",
        "\n",
        "PREDICTIONS = (np.exp(PREDICTIONS)/np.exp(PREDICTIONS).sum(-1,keepdims=True))\n",
        "\n",
        "FEATS = (np.exp(FEATS)/np.exp(FEATS).sum(-1,keepdims=True))\n"
      ],
      "metadata": {
        "id": "7cpGBdNW2rXP"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}