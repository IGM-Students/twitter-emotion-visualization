{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Extract features from a penultimate layer in Emotion English DistilRoBERTa-base model"
      ],
      "metadata": {
        "id": "TgE9B3kso7fQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkIt7_lKp0h-"
      },
      "source": [
        "# install the transformers library\n",
        "!pip install transformers\n",
        "\n",
        "# import required packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# work with cuda\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZNal9hXp6wm"
      },
      "source": [
        "# load tokenizer and model\n",
        "model_name = \"j-hartmann/emotion-english-distilroberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparation of dataset"
      ],
      "metadata": {
        "id": "UArW7snAsKew"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHEzNB5Up5Yc"
      },
      "source": [
        "# create list of texts\n",
        "pred_texts = ['I like that', 'That is annoying', 'This is great!', 'WouldnÂ´t recommend it.']"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(name):\n",
        "    def hook(model, input, output):\n",
        "        features[name] = output.detach()\n",
        "    return hook"
      ],
      "metadata": {
        "id": "17uoYUFSfDHc"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier.dense.register_forward_hook(get_features('feats'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgVs2qkWfJJd",
        "outputId": "4a9912b0-2fd5-4349-f885-dfdb552b04a1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x7f6b70424190>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract features from penultimate layer"
      ],
      "metadata": {
        "id": "GBXclXZitsg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# placeholders\n",
        "PREDICTIONS = []\n",
        "FEATS = []\n",
        "\n",
        "# placeholder for batch features\n",
        "features = {}\n",
        "\n",
        "for idx, inputs in enumerate(pred_texts):\n",
        "     \n",
        "    inputs = tokenizer(inputs, return_tensors=\"pt\")\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    predictions=model(**inputs).logits\n",
        "\n",
        "    PREDICTIONS.append(predictions.detach().cpu().numpy())\n",
        "    FEATS.append(features['feats'].cpu().numpy())\n",
        "       "
      ],
      "metadata": {
        "id": "LEyuTKUp5PW3"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect features\n",
        "\n",
        "PREDICTIONS = np.concatenate(PREDICTIONS)\n",
        "FEATS = np.concatenate(FEATS)\n",
        "\n",
        "print('preds shape:', PREDICTIONS.shape)\n",
        "print('feats shape:', FEATS.shape)"
      ],
      "metadata": {
        "id": "_ybn8Qi74l9P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}